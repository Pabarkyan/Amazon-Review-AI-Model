{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL del ecommerce\n",
    "url = 'https://www.amazon.es/gp/bestsellers/?ref_=nav_cs_bestsellers'\n",
    "# url = 'https://www.amazon.es/b/?_encoding=UTF8&node=76234352031&pd_rd_w=1YVyv&content-id=amzn1.sym.5ad5b890-ecb9-4ef5-8484-3678523450dc&pf_rd_p=5ad5b890-ecb9-4ef5-8484-3678523450dc&pf_rd_r=8NR2MVGA1N49VS8YKG6K&pd_rd_wg=q8U6B&pd_rd_r=dd713508-3446-42f4-8643-a72f56810be7&ref_=pd_hp_d_atf_unk&discounts-widget=%2522%257B%255C%2522state%255C%2522%253A%257B%255C%2522refinementFilters%255C%2522%253A%257B%257D%257D%252C%255C%2522version%255C%2522%253A1%257D%2522'\n",
    "# Obtener el contenido HTML de la página\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Encontrar todos los productos\n",
    "clase_main_bestsellers = \"a-link-normal aok-block\"\n",
    "clase_historial_bestsellers = \"a-link-normal\"\n",
    "productos_main = soup.find_all('a', class_=clase_main_bestsellers)\n",
    "productos_historial = soup.find_all('a', class_=clase_historial_bestsellers)\n",
    "productos = productos_historial + productos_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "# prueba = prueba.get('href')\n",
    "base_url = 'https://www.amazon.com'\n",
    "urls = []\n",
    "for producto in productos:\n",
    "    enlace_absoluto = urljoin(base_url, producto.get('href'))\n",
    "    urls.append(enlace_absoluto)\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el contenido HTML de la página del producto\n",
    "clase = \"a-expander-content reviewText review-text-content a-expander-partial-collapse-content\"\n",
    "\n",
    "todas_las_reseñas = []\n",
    "for url in urls:\n",
    "    response_producto = requests.get(url)\n",
    "    soup_producto = BeautifulSoup(response_producto.text, 'html.parser')\n",
    "    reseñas = soup_producto.find_all('div', class_=clase)\n",
    "    \n",
    "    reseñas_limpias = [] # Para obtener solo el contenido en texto dentro del span que queremos\n",
    "    for reseña in reseñas:\n",
    "        contenido_span = reseña.find('span').text\n",
    "        reseñas_limpias.append(contenido_span)\n",
    "\n",
    "    todas_las_reseñas.append(reseñas_limpias) # añadimos dentro de la lista una lista con todas las reseñas de cada producto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_final = []\n",
    "for i, k in enumerate(todas_las_reseñas):\n",
    "    for j, z in enumerate(k):\n",
    "        if len(z) != 0:\n",
    "            lista_final.append(z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DataFrame(lista_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacamos todas las rutas de \"ver mas\" para obtener la mayor cantidad de productos posibles\n",
    "\n",
    "# Ruta al chromedriver\n",
    "chromedriver_path = r'C:\\Users\\pabma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe'\n",
    "\n",
    "# Inicializa el navegador\n",
    "service = Service(chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "driver.get('https://www.amazon.es/gp/bestsellers/?ref_=nav_cs_bestsellers')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Acceptamos las cookies\n",
    "accept_cokies = driver.find_element(By.ID ,'sp-cc-accept')\n",
    "accept_cokies.click()\n",
    "driver.implicitly_wait(10) # Una espera para evitar errores\n",
    "\n",
    "# a-link-normal\n",
    "urls_econtradas = driver.find_elements(By.CLASS_NAME, 'a-link-normal')\n",
    "urls_ver_mas = []\n",
    "for url in urls_econtradas:\n",
    "    if url.text == 'Ver más':\n",
    "        urls_ver_mas.append(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_ver_mas.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_ver_mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos a intentar conseguir reseñas de mas de un producto de forma automatizada\n",
    "def obtener_reseñas(urls_todos_productos, categoria):\n",
    "    lista_df = []\n",
    "    for url_producto in urls_todos_productos:\n",
    "        driver.get(url_producto.get_attribute('href'))\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        try:\n",
    "            clase_producto = 'a-expander-content reviewText review-text-content a-expander-partial-collapse-content'\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            reseñas_en_div = soup.find_all('div', class_=clase_producto)\n",
    "            nombre_producto = soup.find('span', id='productTitle').text\n",
    "\n",
    "            reseñas = []\n",
    "            for reseña in reseñas_en_div:\n",
    "                if (reseña.find('span').text != 'Video Player is loading.') and (type(reseña.find('span').text) == str): # Algunas reseñas con video daban este mensaje en lugar de la reseña que de nada nos sirve\n",
    "                    # y otras nos daban nones, por lo que podemos filtrar un poco\n",
    "                    reseñas.append(reseña.find('span').text)\n",
    "\n",
    "            producto = pd.DataFrame()\n",
    "            producto['reseñas_humanas'] = reseñas\n",
    "            producto['nombre_producto'] = nombre_producto\n",
    "            producto['categoria_producto'] = categoria # Esto de momento no cambia\n",
    "            lista_df.append(producto)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al extraer información de {url_producto.get_attribute('href')}: {e}\") # obsevamos en que url no ha podido entrar\n",
    "\n",
    "        \n",
    "        driver.back()\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "    combined_df = pd.concat(lista_df, ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUENO\n",
    "lista_df = []\n",
    "clase_link_hijo = 'aok-block'\n",
    "for url_ver_mas in urls_ver_mas:\n",
    "    driver.get(url_ver_mas.get_attribute('href'))\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    urls_todos_productos = driver.find_elements(By.CLASS_NAME, clase_link_hijo)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    categoria_en_div = soup.find('div', class_='_cDEzb_card-title_2sYgw')\n",
    "    categoria = categoria_en_div.find('h1').text\n",
    "\n",
    "    df_ver_mas_individual = obtener_reseñas(urls_todos_productos, categoria) # dentro de este df guardamos todas las reseñas de todos los productos en cada url_ver_mas\n",
    "    lista_df.append(df_ver_mas_individual)\n",
    "\n",
    "    driver.back()\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUENO\n",
    "lista_df_final = []\n",
    "clase_link_hijo = 'aok-block'\n",
    "for url_ver_mas in urls_ver_mas:\n",
    "    driver.get(url_ver_mas.get_attribute('href'))\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    urls_todos_productos = driver.find_elements(By.CLASS_NAME, clase_link_hijo)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    categoria_en_div = soup.find('div', class_='_cDEzb_card-title_2sYgw')\n",
    "    categoria = categoria_en_div.find('h1').text\n",
    "\n",
    "    lista_df = []\n",
    "    for url_producto in urls_todos_productos:\n",
    "        driver.get(url_producto.get_attribute('href'))\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        try:\n",
    "            clase_producto = 'a-expander-content reviewText review-text-content a-expander-partial-collapse-content'\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            reseñas_en_div = soup.find_all('div', class_=clase_producto)\n",
    "            nombre_producto = soup.find('span', id='productTitle').text\n",
    "\n",
    "            reseñas = []\n",
    "            for reseña in reseñas_en_div:\n",
    "                if (reseña.find('span').text != 'Video Player is loading.') and (type(reseña.find('span').text) == str): # Algunas reseñas con video daban este mensaje en lugar de la reseña que de nada nos sirve\n",
    "                    # y otras nos daban nones, por lo que podemos filtrar un poco\n",
    "                    reseñas.append(reseña.find('span').text)\n",
    "\n",
    "            producto = pd.DataFrame()\n",
    "            producto['reseñas_humanas'] = reseñas\n",
    "            producto['nombre_producto'] = nombre_producto\n",
    "            producto['categoria_producto'] = categoria # Esto de momento no cambia\n",
    "            lista_df.append(producto)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al extraer información de {url_producto.get_attribute('href')}: {e}\") # obsevamos en que url no ha podido entrar\n",
    "\n",
    "        \n",
    "        driver.back()\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "    combined_df = pd.concat(lista_df, ignore_index=True)\n",
    "    lista_df_final.append(combined_df)\n",
    "\n",
    "    driver.back()\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las urls de todos los productos dentro de \"ver mas\"\n",
    "clase_link_producto = 'a-link-normal'\n",
    "clase_link_hijo = 'aok-block'\n",
    "# clase_link_producto = 'a-link-normal'\n",
    "urls_ver_mas[0].click()\n",
    "WebDriverWait(driver, 10)\n",
    "urls_todos_productos = driver.find_elements(By.CLASS_NAME, clase_link_hijo)\n",
    "# urls_todos_productos = urls_todos_productos_.find_elements(By.CLASS_NAME, clase_link_hijo)\n",
    "# 3 divs se llaman a-link-normal, uno el de la imagen, otro el del link en si y otro para las reviews del producto, con a-link-normal aok-block solo coge el link de la imagen\n",
    "\n",
    "# Obtenemos la categoria para mas informacion\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# urls_todos_productos = soup.find_all('a', class_=clase_link_producto)\n",
    "categoria_en_div = soup.find('div', class_='_cDEzb_card-title_2sYgw')\n",
    "categoria = categoria_en_div.find('h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_todos_productos[3].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todas las reseñas y el nombre del producto\n",
    "urls_todos_productos[0].click()\n",
    "clase_producto = 'a-expander-content reviewText review-text-content a-expander-partial-collapse-content'\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "reseñas_en_div = soup.find_all('div', class_=clase_producto)\n",
    "nombre_producto = soup.find('span', id='productTitle').text\n",
    "\n",
    "reseñas = []\n",
    "for reseña in reseñas_en_div:\n",
    "    if (reseña.find('span').text != 'Video Player is loading.') and (type(reseña.find('span').text) == str): # Algunas reseñas con video daban este mensaje en lugar de la reseña que de nada nos sirve\n",
    "        # y otras nos daban nones, por lo que podemos filtrar un poco\n",
    "        reseñas.append(reseña.find('span').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el dataset\n",
    "producto = pd.DataFrame()\n",
    "producto['reseñas_humanas'] = reseñas\n",
    "producto['nombre_producto'] = nombre_producto\n",
    "producto['categoria_producto'] = categoria\n",
    "producto\n",
    "\n",
    "# Ideas: Una opción es tener todas las reseñas en una misma columna y tener otra columna que diga con un 0 o 1 si es ia o no, esta opcion\n",
    "# podría ser muy interesante para hacer un modelo de clasificación, la otra opción es tener 2 columnas de reseñas, una con la humana y otra con la ia\n",
    "# creando parejas de reseñas que hablan del mismo producto pero uno escrito por una persona y otro por una ia, este sería interesante para localizar\n",
    "# diferencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo que tenemos hasta ahora funciona, sin embargo tenemos que automatizarlo para que recorra todos los links de las categorias y luego\n",
    "# todos los links de los productos, haga dataframes de cada grupo de reseñas y haga un merge para tener un dataframe mas grande con todas\n",
    "# las reseñas\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_todos_productos[0].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos a intentar conseguir reseñas de mas de un producto de forma automatizada\n",
    "def obtener_reseñas(urls_todos_productos):\n",
    "    lista_df = []\n",
    "    for url_producto in urls_todos_productos:\n",
    "        driver.get(url_producto.get_attribute('href'))\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        try:\n",
    "            clase_producto = 'a-expander-content reviewText review-text-content a-expander-partial-collapse-content'\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            reseñas_en_div = soup.find_all('div', class_=clase_producto)\n",
    "            nombre_producto = soup.find('span', id='productTitle').text\n",
    "\n",
    "            reseñas = []\n",
    "            for reseña in reseñas_en_div:\n",
    "                if (reseña.find('span').text != 'Video Player is loading.') and (type(reseña.find('span').text) == str): # Algunas reseñas con video daban este mensaje en lugar de la reseña que de nada nos sirve\n",
    "                    # y otras nos daban nones, por lo que podemos filtrar un poco\n",
    "                    reseñas.append(reseña.find('span').text)\n",
    "\n",
    "            producto = pd.DataFrame()\n",
    "            producto['reseñas_humanas'] = reseñas\n",
    "            producto['nombre_producto'] = nombre_producto\n",
    "            producto['categoria_producto'] = categoria # Esto de momento no cambia\n",
    "            lista_df.append(producto)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al extraer información de {url_producto.get_attribute('href')}: {e}\") # obsevamos en que url no ha podido entrar\n",
    "\n",
    "        \n",
    "        driver.back()\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "    combined_df = pd.concat(lista_df, ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Service.__del__ at 0x0000023621F972E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 189, in __del__\n",
      "    self.stop()\n",
      "  File \"c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 146, in stop\n",
      "    self.send_remote_shutdown_command()\n",
      "  File \"c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 131, in send_remote_shutdown_command\n",
      "    if not self.is_connectable():\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 120, in is_connectable\n",
      "    return utils.is_connectable(self.port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\utils.py\", line 101, in is_connectable\n",
      "    socket_ = socket.create_connection((host, port), 1)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py\", line 844, in create_connection\n",
      "    exceptions.clear()  # raise only the last error\n",
      "    ^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "## prueba, con esto obtenemos todas las reseñas de todos los productos dentro de un ver mas, hagamos manualmente el proceso con todas las url_ver_mas\n",
    "clase_link_producto = 'a-link-normal'\n",
    "clase_link_hijo = 'aok-block'\n",
    "urls_ver_mas[0].click()\n",
    "WebDriverWait(driver, 10)\n",
    "urls_todos_productos = driver.find_elements(By.CLASS_NAME, clase_link_hijo)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "categoria_en_div = soup.find('div', class_='_cDEzb_card-title_2sYgw')\n",
    "categoria = categoria_en_div.find('h1').text\n",
    "\n",
    "lista_df = []\n",
    "for url_producto in urls_todos_productos:\n",
    "    driver.get(url_producto.get_attribute('href'))\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    try:\n",
    "        clase_producto = 'a-expander-content reviewText review-text-content a-expander-partial-collapse-content'\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        reseñas_en_div = soup.find_all('div', class_=clase_producto)\n",
    "        nombre_producto = soup.find('span', id='productTitle').text\n",
    "\n",
    "        reseñas = []\n",
    "        for reseña in reseñas_en_div:\n",
    "            if (reseña.find('span').text != 'Video Player is loading.') and (type(reseña.find('span').text) == str): # Algunas reseñas con video daban este mensaje en lugar de la reseña que de nada nos sirve\n",
    "                # y otras nos daban nones, por lo que podemos filtrar un poco\n",
    "                reseñas.append(reseña.find('span').text)\n",
    "\n",
    "        producto = pd.DataFrame()\n",
    "        producto['reseñas_humanas'] = reseñas\n",
    "        producto['nombre_producto'] = nombre_producto\n",
    "        producto['categoria_producto'] = categoria # Esto de momento no cambia\n",
    "        lista_df.append(producto)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al extraer información de {url_producto.get_attribute('href')}: {e}\") # obsevamos en que url no ha podido entrar\n",
    "\n",
    "    \n",
    "    driver.back()\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "combined_df = pd.concat(lista_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUENO\n",
    "lista_df = []\n",
    "clase_link_hijo = 'aok-block'\n",
    "for url_ver_mas in urls_ver_mas:\n",
    "    driver.get(url_ver_mas.get_attribute('href'))\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    urls_todos_productos = driver.find_elements(By.CLASS_NAME, clase_link_hijo)\n",
    "\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    categoria_en_div = soup.find('div', class_='_cDEzb_card-title_2sYgw')\n",
    "    categoria = categoria_en_div.find('h1').text\n",
    "\n",
    "    df_ver_mas_individual = obtener_reseñas(urls_todos_productos) # dentro de este df guardamos todas las reseñas de todos los productos en cada url_ver_mas\n",
    "    lista_df.append(df_ver_mas_individual)\n",
    "\n",
    "    driver.back()\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya que podemos sacar las reseñas de todos los productos dentro de un \"ver mas\" hagamos lo mismo pero dentro de ver mas\n",
    "lista_df = []\n",
    "clase_link_hijo = 'aok-block'\n",
    "for url_ver_mas in urls_ver_mas:\n",
    "    driver.get(url_ver_mas.get_attribute('href'))\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    try:\n",
    "        urls_todos_productos = driver.find_elements(By.CLASS_NAME, clase_link_hijo)\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        categoria_en_div = soup.find('div', class_='_cDEzb_card-title_2sYgw')\n",
    "        categoria = categoria_en_div.find('h1').text\n",
    "        \n",
    "\n",
    "        df_ver_mas_individual = obtener_reseñas(urls_todos_productos) # dentro de este df guardamos todas las reseñas de todos los productos en cada url_ver_mas\n",
    "        lista_df.append(df_ver_mas_individual)\n",
    "        driver.implicitly_wait(10)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al extraer información de {e}\") \n",
    "\n",
    "    driver.back()\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lista_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_ver_mas[0].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_todos_productos[2].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(lista_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df['reseñas_humanas'].unique()) # hay 343 reseñas distintas de 30 productos, es una media de 11.43 reseñas por producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reseñas_humanas</th>\n",
       "      <th>nombre_producto</th>\n",
       "      <th>categoria_producto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Funcionan perfectamente luz blanca y bonita pa...</td>\n",
       "      <td>Moxled Guirnaldas Luces Exterior Solar...</td>\n",
       "      <td>Los más vendidos en Iluminación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Las compré para el jardin y aguantan todo tipo...</td>\n",
       "      <td>Moxled Guirnaldas Luces Exterior Solar...</td>\n",
       "      <td>Los más vendidos en Iluminación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Son más pequeñas de lo que quería, pero son gr...</td>\n",
       "      <td>Moxled Guirnaldas Luces Exterior Solar...</td>\n",
       "      <td>Los más vendidos en Iluminación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buen producto. Relación calidad- precio muy bu...</td>\n",
       "      <td>Moxled Guirnaldas Luces Exterior Solar...</td>\n",
       "      <td>Los más vendidos en Iluminación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Muy chulas</td>\n",
       "      <td>Moxled Guirnaldas Luces Exterior Solar...</td>\n",
       "      <td>Los más vendidos en Iluminación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>We bought this for our 10 year old son for Chr...</td>\n",
       "      <td>Gritin 19 LED Luz de Lectura, 360° Fle...</td>\n",
       "      <td>Los más vendidos en Iluminación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>This light is small yet mighty.  I love the fe...</td>\n",
       "      <td>Gritin 19 LED Luz de Lectura, 360° Fle...</td>\n",
       "      <td>Los más vendidos en Iluminación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Mi principal problema al leer es encontrar bue...</td>\n",
       "      <td>Gritin 19 LED Luz de Lectura, 360° Fle...</td>\n",
       "      <td>Los más vendidos en Iluminación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Batteriet håller länge efter första användning...</td>\n",
       "      <td>Gritin 19 LED Luz de Lectura, 360° Fle...</td>\n",
       "      <td>Los más vendidos en Iluminación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Excellent for reading in bed so I don’t wake m...</td>\n",
       "      <td>Gritin 19 LED Luz de Lectura, 360° Fle...</td>\n",
       "      <td>Los más vendidos en Iluminación</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       reseñas_humanas  \\\n",
       "0    Funcionan perfectamente luz blanca y bonita pa...   \n",
       "1    Las compré para el jardin y aguantan todo tipo...   \n",
       "2    Son más pequeñas de lo que quería, pero son gr...   \n",
       "3    Buen producto. Relación calidad- precio muy bu...   \n",
       "4                                           Muy chulas   \n",
       "..                                                 ...   \n",
       "365  We bought this for our 10 year old son for Chr...   \n",
       "366  This light is small yet mighty.  I love the fe...   \n",
       "367  Mi principal problema al leer es encontrar bue...   \n",
       "368  Batteriet håller länge efter första användning...   \n",
       "369  Excellent for reading in bed so I don’t wake m...   \n",
       "\n",
       "                                       nombre_producto  \\\n",
       "0            Moxled Guirnaldas Luces Exterior Solar...   \n",
       "1            Moxled Guirnaldas Luces Exterior Solar...   \n",
       "2            Moxled Guirnaldas Luces Exterior Solar...   \n",
       "3            Moxled Guirnaldas Luces Exterior Solar...   \n",
       "4            Moxled Guirnaldas Luces Exterior Solar...   \n",
       "..                                                 ...   \n",
       "365          Gritin 19 LED Luz de Lectura, 360° Fle...   \n",
       "366          Gritin 19 LED Luz de Lectura, 360° Fle...   \n",
       "367          Gritin 19 LED Luz de Lectura, 360° Fle...   \n",
       "368          Gritin 19 LED Luz de Lectura, 360° Fle...   \n",
       "369          Gritin 19 LED Luz de Lectura, 360° Fle...   \n",
       "\n",
       "                  categoria_producto  \n",
       "0    Los más vendidos en Iluminación  \n",
       "1    Los más vendidos en Iluminación  \n",
       "2    Los más vendidos en Iluminación  \n",
       "3    Los más vendidos en Iluminación  \n",
       "4    Los más vendidos en Iluminación  \n",
       "..                               ...  \n",
       "365  Los más vendidos en Iluminación  \n",
       "366  Los más vendidos en Iluminación  \n",
       "367  Los más vendidos en Iluminación  \n",
       "368  Los más vendidos en Iluminación  \n",
       "369  Los más vendidos en Iluminación  \n",
       "\n",
       "[370 rows x 3 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls_ver_mas) # por cada url de ver mas hay unos 343 productos y tenemos 6 urls, por lo tanto tendriamos aproximadamente 2058 muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['categoria_producto'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_df) - combined_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_df['reseñas_humanas'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parece que hay un monton de duplicados, por lo visto se repiten 4 veces por algun motivo y parece que solo tiene 30 productos diferentes\n",
    "# cuando creo que deberia tener 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls_todos_productos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comprobacion = pd.DataFrame()\n",
    "df_comprobacion['urls'] = urls_todos_productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comprobacion['urls'].duplicated().sum() # Son todo urls distintas, porque entonces hay tantos pocos uniques en nombre, si tendria que haber las \n",
    "# mismas url que nombres de productos aunque haya muchos duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seccion in urls_ver_mas:\n",
    "    try:\n",
    "        seccion.click()\n",
    "        url_productos = driver.find_elements(By.CLASS_NAME, 'a-link-normal')\n",
    "        for producto in url_productos:\n",
    "            reseñas_producto = []\n",
    "            producto.click()\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            reseñas = soup_producto.find_all('div', class_=clase)\n",
    "    \n",
    "            reseñas_limpias = [] # Para obtener solo el contenido en texto dentro del span que queremos\n",
    "            for reseña in reseñas:\n",
    "                contenido_span = reseña.find('span').text\n",
    "                reseñas_limpias.append(contenido_span)\n",
    "\n",
    "            todas_las_reseñas.append(reseñas_limpias)\n",
    "    except:\n",
    "        print(\"Se produjo un error\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_las_reseñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "# Configuración del navegador\n",
    "\n",
    "# Ruta al chromedriver\n",
    "chromedriver_path = r'C:\\Users\\pabma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe'\n",
    "\n",
    "# Inicializa el navegador\n",
    "service = Service(chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "driver.get('https://www.amazon.es/gp/bestsellers/?ref_=nav_cs_bestsellers')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Aceptar cookies si es necesario\n",
    "try:\n",
    "    accept_button = driver.find_element(By.ID ,'sp-cc-accept')\n",
    "    accept_button.click()\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "# Esperar hasta que los elementos estén presentes\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# Encontrar los elementos \"Ver más\"\n",
    "urls_ver_mas = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//a[@class='a-link-normal' and text()='Ver más']\")))\n",
    "\n",
    "for seccion in urls_ver_mas:\n",
    "    try:\n",
    "        seccion.click()\n",
    "        # Esperar a que se carguen los elementos de los productos\n",
    "        wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//a[@class='a-link-normal']\")))\n",
    "        url_productos = driver.find_elements(By.XPATH, \"//a[@class='a-link-normal']\")\n",
    "        for producto in url_productos:\n",
    "            reseñas_producto = []\n",
    "            producto.click()\n",
    "            # Esperar a que se carguen los elementos de las reseñas\n",
    "            wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//div[@class='a-expander-content reviewText review-text-content a-expander-partial-collapse-content']\")))\n",
    "            reseñas = driver.find_elements(By.XPATH, \"//div[@class='a-expander-content reviewText review-text-content a-expander-partial-collapse-content']\")\n",
    "            for reseña in reseñas:\n",
    "                contenido = reseña.find_element(By.XPATH, \".//span\")\n",
    "                texto = contenido.text\n",
    "                reseñas_producto.append(texto)\n",
    "            print(reseñas_producto)  # Opcional: Imprime las reseñas para este producto\n",
    "    except NoSuchElementException:\n",
    "        print(\"No se pudo encontrar el elemento 'Ver más'\")\n",
    "    except TimeoutException:\n",
    "        print(\"Tiempo de espera agotado para cargar los elementos\")\n",
    "    finally:\n",
    "        driver.back()  # Regresa a la página de bestsellers para continuar con la siguiente sección\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseñas_producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsada\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import time\n",
    "\n",
    "# # Configurar Selenium con el controlador de Chrome\n",
    "# # service = Service('/Users/pabma/Downloads/chrome-win32/.exe')  # Reemplaza con la ruta a tu ChromeDriver\n",
    "# # driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# service = webdriver.ChromeService(port=1234)\n",
    "# driver = webdriver.Chrome(service=service)\n",
    "# # driver = webdriver.Chrome()\n",
    "\n",
    "# # URL de la página\n",
    "# url = 'https://www.example.com'  # Reemplaza con la URL de tu página\n",
    "\n",
    "# # Navegar a la página\n",
    "# driver.get(enlace_absoluto)\n",
    "\n",
    "# # Esperar a que el contenido se cargue completamente\n",
    "# # Ajusta el tiempo de espera según sea necesario\n",
    "# wait = WebDriverWait(driver, 10)\n",
    "# review_div = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-a-expander-name=\"review_text_read_more\"]')))\n",
    "\n",
    "# # Hacer clic en el botón para expandir la reseña si es necesario\n",
    "# expand_button = review_div.find_element(By.CSS_SELECTOR, '.a-expander-header')\n",
    "# expand_button.click()\n",
    "\n",
    "# # Esperar a que el contenido expandido se cargue\n",
    "# expanded_content = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-hook=\"review-collapsed\"]')))\n",
    "\n",
    "# # Encontrar el <span> dentro del div expandido\n",
    "# span = expanded_content.find_element(By.CSS_SELECTOR, 'span')\n",
    "\n",
    "# # Obtener el texto del <span>\n",
    "# span_text = span.text\n",
    "\n",
    "# # Imprimir el contenido del <span>\n",
    "# print(span_text)\n",
    "\n",
    "# # Cerrar el navegador\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "\n",
    "\n",
    "# def test_basic_service():\n",
    "#     service = webdriver.ChromeService()\n",
    "#     driver = webdriver.Chrome(service=service)\n",
    "\n",
    "#     driver.quit()\n",
    "\n",
    "\n",
    "# def test_driver_location(chromedriver_bin, chrome_bin):\n",
    "#     options = webdriver.ChromeOptions()\n",
    "#     options.binary_location = chrome_bin\n",
    "\n",
    "#     service = webdriver.ChromeService(executable_path=chromedriver_bin)\n",
    "\n",
    "#     driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "#     driver.quit()\n",
    "\n",
    "\n",
    "# def test_driver_port():\n",
    "#     service = webdriver.ChromeService(port=1234)\n",
    "\n",
    "#     driver = webdriver.Chrome(service=service)\n",
    "\n",
    "#     driver.quit()\n",
    "\n",
    "\n",
    "# test_driver_port()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "\n",
    "service = webdriver.ChromeService(port=1234)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "try:\n",
    "    # Navega a la página de e-commerce\n",
    "    driver.get('https://www.amazon.es/gp/bestsellers/?ref_=nav_cs_bestsellers')\n",
    "\n",
    "    # Espera a que la página cargue completamente\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Localiza el botón de la flecha (esto puede variar según la estructura del sitio web)\n",
    "    flecha_derecha = driver.find_elements(By.CLASS_NAME, 'a-button a-button-image a-carousel-button a-carousel-goto-nextpage')\n",
    "\n",
    "    # Haz clic en la flecha para desplazar el carrusel\n",
    "    NUMERO_DE_CLICKS = 1\n",
    "    for i in flecha_derecha:\n",
    "        i.click()\n",
    "        time.sleep(2)  # Espera un poco para que el carrusel se desplace\n",
    "\n",
    "    # Ahora extrae los elementos visibles en el carrusel\n",
    "    items_carrusel = driver.find_elements(By.CLASS_NAME, clase_main_bestsellers)\n",
    "\n",
    "    for item in items_carrusel:\n",
    "        # Aquí puedes procesar cada item como desees, por ejemplo:\n",
    "        print(item.text)\n",
    "\n",
    "finally:\n",
    "    # Cierra el navegador\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "# Configuración del navegador\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Ejecuta el navegador en modo headless (sin interfaz gráfica)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Ruta al chromedriver\n",
    "chromedriver_path = r'C:\\Users\\pabma\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe'\n",
    "\n",
    "# Inicializa el navegador\n",
    "service = Service(chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Espera a que la página cargue completamente\n",
    "    driver.get('https://www.amazon.es/gp/bestsellers/?ref_=nav_cs_bestsellers')\n",
    "\n",
    "    try:\n",
    "        consent_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"sp-cc-accept\"))\n",
    "        )\n",
    "        consent_button.click()\n",
    "    except (TimeoutException, NoSuchElementException):\n",
    "        print(\"No se encontró el botón de consentimiento de cookies.\")\n",
    "\n",
    "    # Localiza todas las filas del carrusel\n",
    "    filas_carrusel = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CLASS_NAME, 'a-carousel-row-inner'))\n",
    "    )\n",
    "    print(filas_carrusel)\n",
    "\n",
    "    # Para cada fila en el carrusel\n",
    "    for fila in filas_carrusel:\n",
    "        # Localiza todas las flechas dentro de esta fila\n",
    "        try:\n",
    "            flechas = fila.find_elements(By.CLASS_NAME, 'a-carousel-goto-nextpage')\n",
    "            print(flechas)\n",
    "            # Haz clic en cada flecha de la fila y extrae los elementos visibles\n",
    "            for flecha in flechas:\n",
    "                flecha.click()\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.CLASS_NAME, clase_main_bestsellers))\n",
    "                )\n",
    "\n",
    "                # Extrae los elementos visibles en el carrusel por su nombre de clase\n",
    "                items_carrusel = fila.find_elements(By.CLASS_NAME, clase_historial_bestsellers)\n",
    "\n",
    "                for item in items_carrusel:\n",
    "                    # Aquí puedes procesar cada item como desees, por ejemplo:\n",
    "                    print(item.text)\n",
    "\n",
    "        except NoSuchElementException as e:\n",
    "            print(f\"Error al localizar las flechas: {e}\")\n",
    "\n",
    "except TimeoutException as e:\n",
    "    print(f\"Tiempo de espera agotado para cargar los elementos: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Cierra el navegador\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_carrusel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
